{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28277,
     "status": "ok",
     "timestamp": 1745000147629,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "6Eci6W-3Yt0b",
    "outputId": "bea583ea-e0ed-4459-c030-6057594962a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1745000454785,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "mmKf6vuEZU6j",
    "outputId": "322fcd26-6dd0-4d43-e5a3-dcf38ea638c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Load processed sequence data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "project_root = \"/content/drive/MyDrive/FraudBehaviorEmbeddings\"\n",
    "input_path = os.path.join(project_root, \"data/processed/transformer_input.pkl\")\n",
    "df = pd.read_pickle(input_path)#deserialize pickel\n",
    "\n",
    "# Convert to list format\n",
    "sequences = list(df['padded_sequence'].values)\n",
    "labels = list(df['label_encoded'].values)\n",
    "# print(sequences)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_24VAeG-ZrBu"
   },
   "source": [
    "Install Hugging face transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3015,
     "status": "ok",
     "timestamp": 1745000658276,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "urulAvhwZwUc"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9tptwGdJTb-"
   },
   "source": [
    "PREPARE dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745004396460,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "lnBuQxE5ZYiq"
   },
   "outputs": [],
   "source": [
    "#STEP 4  Prepare datasets\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.sequences[idx],\n",
    "            'attention_mask': (self.sequences[idx] != 0).long(),  # padding mask\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(sequences, labels, test_size=0.2, stratify=labels)\n",
    "\n",
    "train_data = FraudDataset(X_train, y_train)\n",
    "val_data = FraudDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiYIadr4Xojp"
   },
   "source": [
    "LOAD TRANSFORMER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1745007596822,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "OnmLZ60hbaJc"
   },
   "outputs": [],
   "source": [
    "# Load DistilBERT Model\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
    "\n",
    "num_labels = df['label_encoded'].nunique()\n",
    "# print(num_labels)\n",
    "\n",
    "config = DistilBertConfig(\n",
    " vocab_size=30522,    # Number of tokens DistilBERT understands\n",
    "    n_heads=8,           # Number of attention heads (parallel attention mechanisms)\n",
    "    dim=512,             # Hidden size of each token representation (default for DistilBERT)\n",
    "    hidden_dim=2048,     # Size of feed-forward layers inside the Transformer block\n",
    "    n_layers=6,          # Number of Transformer layers\n",
    "    # num_labels=num_labels  # Number of output classes for classification\n",
    " num_labels=3# this provided me error in the training phase\n",
    "\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4140,
     "status": "ok",
     "timestamp": 1745007605937,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "Qhif_eDibciC",
    "outputId": "77bb149c-f9dd-4b3b-cf44-fb903cb66970"
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\" Epoch {epoch+1} - Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1745007762204,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "y9OeaJbfdTzN",
    "outputId": "136811e5-f930-4fcc-b5c9-7c4bbb9ab9e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved model to /content/drive/MyDrive/FraudBehaviorEmbeddings/models/transformer/distilbert_fraud.pt\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Save model\n",
    "model_path = os.path.join(project_root, \"models/transformer/distilbert_fraud.pt\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\" Saved model to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN97p/YqTQ8QsMVhqZqF7zd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
