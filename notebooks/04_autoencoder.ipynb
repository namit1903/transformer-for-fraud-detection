{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112990,
     "status": "ok",
     "timestamp": 1745100921212,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "gBgBP4ez0bLs",
    "outputId": "6088eb46-2dcd-4212-812f-ec5447b38c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7831,
     "status": "ok",
     "timestamp": 1745102221181,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "27XXxdHD0uT6",
    "outputId": "3a8c416d-c63c-4a29-9d6b-ad0f5963addc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "root = \"/content/drive/MyDrive/FraudBehaviorEmbeddings\"\n",
    "embeddings = np.load(os.path.join(root, \"data/processed/graphsage_embeddings.npy\"))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRkQtsvB1CKA"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "\n",
    "# project_root = \"/content/drive/MyDrive/FraudBehaviorEmbeddings\"\n",
    "# embeddings_path = os.path.join(project_root, \"models/transformer/user_embeddings.pkl\")\n",
    "\n",
    "# with open(embeddings_path, 'rb') as f:\n",
    "#     embeddings = pickle.load(f)\n",
    "\n",
    "# # Convert dict of subscriber_id -> embedding to DataFrame\n",
    "# df_embed = pd.DataFrame.from_dict(embeddings, orient='index')\n",
    "# df_embed.reset_index(inplace=True)\n",
    "# df_embed.rename(columns={'index': 'subscriber_id'}, inplace=True)\n",
    "\n",
    "# print(\"Embeddings Loaded:\")\n",
    "# df_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7561,
     "status": "ok",
     "timestamp": 1745102285479,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "GvsZyNh91TRX"
   },
   "outputs": [],
   "source": [
    "#Converting to torch tensor\n",
    "X = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "# Define Autoencoder class inheriting nn i.e  neural network module\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, bottleneck_dim=8):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, bottleneck_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out, z\n",
    "\n",
    "model = Autoencoder(input_dim=X.shape[1], bottleneck_dim=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2sz__clM7Lw"
   },
   "source": [
    "TRAINING AUTOENCODERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1745062450081,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "IrG4Qw6D05bK",
    "outputId": "2f10e5b6-14e7-4ca7-e59d-37591c0f9cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0191\n",
      "Epoch 10, Loss: 0.0092\n",
      "Epoch 20, Loss: 0.0038\n",
      "Epoch 30, Loss: 0.0012\n",
      "Epoch 40, Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Train autoencoder\n",
    "def train_autoencoder(X, model, optimizer, criterion, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "train_autoencoder(X, model, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1745103184462,
     "user": {
      "displayName": "Namit",
      "userId": "08031843768376211005"
     },
     "user_tz": -330
    },
    "id": "coCHBy7N0_kw",
    "outputId": "10cb329c-4cfe-4436-9312-1a9cdb94f055"
   },
   "outputs": [],
   "source": [
    "# Saving compressed embeddings\n",
    "model.eval()\n",
    "prediction_score, compressed_embeddings = model(X)\n",
    "# print(compressed_embeddings)#==>this is tensor\n",
    "compressed_np = compressed_embeddings.detach().numpy()\n",
    "# print(compressed_np)-->this is array or numpy array\n",
    "# When you call .detach() on a tensor:\n",
    "\n",
    "# It returns a new tensor with the same data\n",
    "\n",
    "# But gradients won't be tracked for it anymore\n",
    "\n",
    "# Useful when you're not training, just using the output\n",
    "\n",
    "\n",
    "# print(\"prediction scores=>\",prediction_score)\n",
    "\n",
    "np.save(os.path.join(root, \"data/processed/compressed_embeddings.npy\"), compressed_np)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLknGSXZU41U7idbhvzCj7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
