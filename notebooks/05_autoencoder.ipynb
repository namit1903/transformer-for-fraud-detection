{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLknGSXZU41U7idbhvzCj7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBgBP4ez0bLs","executionInfo":{"status":"ok","timestamp":1745100921212,"user_tz":-330,"elapsed":112990,"user":{"displayName":"Namit","userId":"08031843768376211005"}},"outputId":"6088eb46-2dcd-4212-812f-ec5447b38c73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["# ðŸ“Œ STEP 1: Imports\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import os\n","\n","root = \"/content/drive/MyDrive/FraudBehaviorEmbeddings\"\n","embeddings = np.load(os.path.join(root, \"data/processed/graphsage_embeddings.npy\"))\n","embeddings.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27XXxdHD0uT6","executionInfo":{"status":"ok","timestamp":1745102221181,"user_tz":-330,"elapsed":7831,"user":{"displayName":"Namit","userId":"08031843768376211005"}},"outputId":"3a8c416d-c63c-4a29-9d6b-ad0f5963addc"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18, 16)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# import os\n","# import pandas as pd\n","# import pickle\n","\n","# project_root = \"/content/drive/MyDrive/FraudBehaviorEmbeddings\"\n","# embeddings_path = os.path.join(project_root, \"models/transformer/user_embeddings.pkl\")\n","\n","# with open(embeddings_path, 'rb') as f:\n","#     embeddings = pickle.load(f)\n","\n","# # Convert dict of subscriber_id -> embedding to DataFrame\n","# df_embed = pd.DataFrame.from_dict(embeddings, orient='index')\n","# df_embed.reset_index(inplace=True)\n","# df_embed.rename(columns={'index': 'subscriber_id'}, inplace=True)\n","\n","# print(\"âœ… Embeddings Loaded:\")\n","# df_embed.head()"],"metadata":{"id":"cRkQtsvB1CKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ðŸ“Œ STEP 2: Convert to torch tensor\n","X = torch.tensor(embeddings, dtype=torch.float32)\n","\n","# ðŸ“Œ STEP 3: Define Autoencoder\n","class Autoencoder(nn.Module):\n","    def __init__(self, input_dim, bottleneck_dim=8):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, bottleneck_dim)\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(bottleneck_dim, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, input_dim)\n","        )\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        out = self.decoder(z)\n","        return out, z\n","\n","model = Autoencoder(input_dim=X.shape[1], bottleneck_dim=8)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()"],"metadata":{"id":"GvsZyNh91TRX","executionInfo":{"status":"ok","timestamp":1745102285479,"user_tz":-330,"elapsed":7561,"user":{"displayName":"Namit","userId":"08031843768376211005"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["TRAINING AUTOENCODERS"],"metadata":{"id":"d2sz__clM7Lw"}},{"cell_type":"code","source":["# ðŸ“Œ STEP 4: Train autoencoder\n","def train_autoencoder(X, model, optimizer, criterion, epochs=50):\n","    for epoch in range(epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        output, _ = model(X)\n","        loss = criterion(output, X)\n","        loss.backward()\n","        optimizer.step()\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n","\n","train_autoencoder(X, model, optimizer, criterion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrG4Qw6D05bK","executionInfo":{"status":"ok","timestamp":1745062450081,"user_tz":-330,"elapsed":330,"user":{"displayName":"Namit","userId":"08031843768376211005"}},"outputId":"2f10e5b6-14e7-4ca7-e59d-37591c0f9cbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.0191\n","Epoch 10, Loss: 0.0092\n","Epoch 20, Loss: 0.0038\n","Epoch 30, Loss: 0.0012\n","Epoch 40, Loss: 0.0002\n"]}]},{"cell_type":"code","source":["#  STEP 5: Save compressed embeddings\n","model.eval()\n","p, compressed_embeddings = model(X)\n","# print(compressed_embeddings)#==>this is tensor\n","compressed_np = compressed_embeddings.detach().numpy()\n","# print(compressed_np)-->this is array or numpy array\n","# When you call .detach() on a tensor:\n","\n","# It returns a new tensor with the same data\n","\n","# But gradients won't be tracked for it anymore\n","\n","# Useful when you're not training, just using the output\n","\n","\n","# print(\"prediction scores=>\",p)\n","\n","np.save(os.path.join(root, \"data/processed/compressed_embeddings.npy\"), compressed_np)\n","print(\"Compressed embeddings saved!\")\n"],"metadata":{"id":"coCHBy7N0_kw","executionInfo":{"status":"ok","timestamp":1745103184462,"user_tz":-330,"elapsed":21,"user":{"displayName":"Namit","userId":"08031843768376211005"}},"outputId":"10cb329c-4cfe-4436-9312-1a9cdb94f055","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Compressed embeddings saved!\n"]}]}]}